cov.names = c("age",
"sex", "cursmoke"),
arcs = c(
0, -1, # exposure (sysbp) --> outcome (cvd)
1,  0,
2,  0,
3,  0,
1, -1,
2, -1,
3, -1
)
)
return(dag)
}
dag.draw(srh.dag(), noxy=2)
srh.dag <- function() {
dag <- dag.init(y.name = "cvd", x.name = "sysbp",
covs = rep(1, 3),
cov.names = c("age",
"sex", "cursmoke"),
arcs = c(
0, -1, # exposure (sysbp) --> outcome (cvd)
1,  0,
1,  2,
2,  0,
3,  0,
1, -1,
2, -1,
3, -1
)
)
return(dag)
}
dag.draw(srh.dag(), noxy=2)
srh.dag <- function() {
dag <- dag.init(y.name = "cvd", x.name = "sysbp",
covs = rep(1, 3),
cov.names = c("age",
"sex", "cursmoke"),
arcs = c(
0, -1, # exposure (sysbp) --> outcome (cvd)
1,  0,
1,  3,
2,  0,
3,  0,
1, -1,
2, -1,
3, -1
)
)
return(dag)
}
dag.draw(srh.dag(), noxy=2)
cvd.dag <- function() {
dag <- dag.init(y.name = "cvd", x.name = "sysbp",
covs = rep(1, 3),
cov.names = c("age",
"sex", "cursmoke"),
arcs = c(
0, -1, # exposure (sysbp) --> outcome (cvd)
1,  0,
1,  3,
2,  0,
3,  0,
1, -1,
2, -1,
3, -1
)
)
return(dag)
}
dag.draw(cvd.dag(), noxy=2)
rm(srh.dag)
?str
str(framingham)
library(Epi)
install.packages("Epi")
library(Epi)
library(plyr)
install.packages("plyr")
install.packages("survival")
library(survival)
for (i in 1:ncol(framingham))
attr(framingham[,i], "names") <- NULL
## Unadjusted unmatched case-control estimate and (asymptotic)
## variance estimate:
my.cc.log.or <- function(n01, n11, n00, n10) log(n11 / n01 / (n10 / n00))
my.cc.log.or.var <- function(n01, n11, n00, n10) 1/n11 + 1/n01 + 1/n10 + 1/n00
with(framingham, table(cvd, sysbp))
for (i in 1:ncol(framingham))
attr(framingham[,i], "names") <- NULL
## Unadjusted unmatched case-control estimate and (asymptotic)
## variance estimate:
my.cc.log.or <- function(n01, n11, n00, n10) log(n11 / n01 / (n10 / n00))
my.cc.log.or.var <- function(n01, n11, n00, n10) 1/n11 + 1/n01 + 1/n10 + 1/n00
with(framingham, table(cvd, cursmoke))
time.1st <- within(subset(framingham, period==2, select=c(randid, time)), {
time.1st <- time
rm(time)
})
time.2nd <- within(subset(framingham, period==3, select=c(randid, time)), {
time.1st <- time
rm(time)
})
framingham <- merge(framingham, time.1st, time.2nd)
time.1st <- within(subset(framingham, period==2, select=c(randid, time)), {
time.1st <- time
rm(time)
})
time.2nd <- within(subset(framingham, period==3, select=c(randid, time)), {
time.2nd <- time
rm(time)
})
framingham <- merge(framingham, time.1st, time.2nd)
framingham <- merge(framingham, time.1st)
framingham <- merge(framingham, time.2nd)
time.3rd <- within(subset(framingham, period==4, select=c(randid, time)), {
time.3rd <- time
rm(time)
})
time.base <- within(subset(framingham, period==1, select=c(randid, time)), {
time.base <- time
rm(time)
})
case.id <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1,
select=randid)
case.id2 <- subset(framingham, timecvd>0 & timecvd < time.2nd &
period==2,
select=randid)
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevsrtk==0,
select=randid)
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
case.id2 <- subset(framingham, timecvd>0 & timecvd < time.2nd &
period==2 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
uusi <- merge(case.id1, case.id2)
uusi <- merge(case.id1, case.id2, by="randid")
uusi <- merge(framingham, case.id1)
uusi <- merge(framingham, case.id2)
uusi1 <- merge(framingham, case.id1, by="randid")
rm(case.id)
rm(time.3rd)
rm(uusi)
rm(uusi1)
View(case.id1)
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid,timecvd)
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevstrk==0)
case.id2 <- subset(framingham, timecvd>0 & timecvd < time.2nd &
period==2 & prevchd==0 & prevmi==0 & prevstrk==0)
uusi1 <- merge(case.id1, case.id2, by="randid")
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
case.id2 <- subset(framingham, timecvd>0 & timecvd < time.2nd &
period==2 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
rm(uusi1)
uusi <- rbind(case.id1, case.id2)
load("~/SMIPH/framingham.Rdata")
attach(framingham)
names(framingham)
11627/4439
library(dagR)
cvd.dag <- function() {
dag <- dag.init(y.name = "cvd", x.name = "sysbp",
covs = rep(1, 3),
cov.names = c("age",
"sex", "cursmoke"),
arcs = c(
0, -1, # exposure (sysbp) --> outcome (cvd)
1,  0,
1,  3,
2,  0,
3,  0,
1, -1,
2, -1,
3, -1
)
)
return(dag)
}
dag.draw(cvd.dag(), noxy=2)
str(framingham)
library(Epi)
library(plyr)
library(survival)
#Control cases
time.1st <- within(subset(framingham, period==2, select=c(randid, time)), {
time.1st <- time
rm(time)
})
time.2nd <- within(subset(framingham, period==3, select=c(randid, time)), {
time.2nd <- time
rm(time)
})
framingham <- merge(framingham, time.1st)
framingham <- merge(framingham, time.2nd)
time.base <- within(subset(framingham, period==1, select=c(randid, time)), {
time.base <- time
rm(time)
})
case.id1 <- subset(framingham, timecvd>0 & timecvd < time.1st &
period==1 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
case.id2 <- subset(framingham, timecvd>0 & timecvd < time.2nd &
period==2 & prevchd==0 & prevmi==0 & prevstrk==0,
select=randid)
uusi <- rbind(case.id1, case.id2)
for (i in 1:ncol(framingham))
attr(framingham[,i], "names") <- NULL
## Unadjusted unmatched case-control estimate and (asymptotic)
## variance estimate:
my.cc.log.or <- function(n01, n11, n00, n10) log(n11 / n01 / (n10 / n00))
my.cc.log.or.var <- function(n01, n11, n00, n10) 1/n11 + 1/n01 + 1/n10 + 1/n00
with(framingham, table(cvd, cursmoke))
var.v <- list(age, sex, cursmoke)
for (i in var.v) {
## Association with the risk factor:
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", i, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", i, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(i, o.p, r.p, "\n")
}
}
for (i in var.v) {
## Association with the risk factor:
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", i, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", i, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(i, o.p, r.p, "\n")
}
}
for (i in 1:ncol(framingham))
attr(framingham[,i], "names") <- NULL
var.v <- list(age, sex, cursmoke)
for (i in var.v) {
## Association with the risk factor:
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", i, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", i, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(i, o.p, r.p, "\n")
}
}
for (i in 1:ncol(framingham))
attr(framingham[,i], "names") <- NULL
var.v <- c("age", "sex", "cursmoke")
for (i in var.v) {
## Association with the risk factor:
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", i, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", i, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(i, o.p, r.p, "\n")
}
}
var.v <- list(age, sex, cursmoke)
for (i in var.v) {
## Association with the risk factor:
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", i, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", i, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(i, o.p, r.p, "\n")
}
}
r.p <- eval(parse(text=paste0("with(framingham, fisher.test(sysbp, ", age, ")$p.value)")))
## Association with the outcome:
o.p <- eval(parse(text=paste0("with(framingham, fisher.test(cvd, ", age, ")$p.value)")))
if (o.p < 0.10 && r.p < 0.10) {
## Choose variables with both p-values below 0.10:
cat(age, o.p, r.p, "\n")
library(survival)
p
)
library(survival)
d <- subset(framingham, time==0 & prevchd==0 & prevmi==0 & prevstrk==0)
res <- coxph(Surv(timecvd, cvd) ~ sysbp, data=d)
summary(res)
res2 <- coxph(Surv(timecvd, cvd) ~ sysbp + age, data=d)
summary(res2)
res3 <- coxph(Surv(timecvd, cvd) ~ sysbp + sex, data=d)
summary(res3)
res4 <- coxph(Surv(timecvd, cvd) ~ sysbp + cursmoke, data=d)
summary(res4)
res5 <- coxph(Surv(timecvd, cvd) ~ sysbp + age + sex, data=d)
summary(res5)
res5 <- coxph(Surv(timecvd, cvd) ~ sysbp + age + cursmoke, data=d)
summary(res5)
res6 <- coxph(Surv(timecvd, cvd) ~ sysbp + sex + cursmoke, data=d)
summary(res6)
res7 <- coxph(Surv(timecvd, cvd) ~ sysbp + age + sex + cursmoke, data=d)
summary(res7)
cox.zph(res)
cox.zph(res7)
res <- coxph(Surv(time, totchol) ~ age, data=d)
names(framingham)
res <- coxph(Surv(time, totchol) ~ age, data=d)
res <- coxph(Surv(timecvd, totchol) ~ age, data=d)
res
res8 <- coxph(Surv(time, totchol) ~ age, data=d)
res8 <- coxph(Surv(time, cvd) ~ age, data=d)
summary(res8)
reg0 <- survreg(Surv(time, age, totchol) ~ 1, data=d)
summary(reg0)
reg0 <- survreg(Surv(age, totchol) ~ 1, data=d)
reg0 <- survreg(Surv(age, totchol) ~ 1, data=d, dist="exponential")
summary(totchol)
my.cc.log.or <- function(n01, n11, n00, n10) log(n11 / n01 / (n10 / n00))
my.cc.log.or.var <- function(n01, n11, n00, n10) 1/n11 + 1/n01 + 1/n10 + 1/n00
with(framingham, table(cvd, cursmoke))
framingham <- within(framingham, {
cc.group <- factor(NA, levels=c("Case", "Control", "Excluded"))
cc.group[timecvd>0 & timecvd < time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Case"
cc.group[timecvd >= time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Control"
## Exclude deaths before 1st follow-up point and prevalent cases:
cc.group[timedth < time.1st | prevchd==1 | prevmi==1 | prevstrk==1] <- "Excluded"
})
control.id <- dlply(framingham,
.(agegr=cut(age, 3:7*10)),
function(x) with(x, sample(randid[cc.group=="Control"],
sum(cc.group=="Case"))))
library(dplyr)
install.packages("plyr")
framingham <- within(framingham, {
cc.group <- factor(NA, levels=c("Case", "Control", "Excluded"))
cc.group[timecvd>0 & timecvd < time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Case"
cc.group[timecvd >= time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Control"
## Exclude deaths before 1st follow-up point and prevalent cases:
cc.group[timedth < time.1st | prevchd==1 | prevmi==1 | prevstrk==1] <- "Excluded"
})
control.id <- dlply(framingham,
.(agegr=cut(age, 3:7*10)),
function(x) with(x, sample(randid[cc.group=="Control"],
sum(cc.group=="Case"))))
library(plyr)
#finding the control group by using frequency sampling
framingham <- within(framingham, {
cc.group <- factor(NA, levels=c("Case", "Control", "Excluded"))
cc.group[timecvd>0 & timecvd < time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Case"
cc.group[timecvd >= time.1st & prevchd==0 & prevmi==0 & prevstrk==0] <- "Control"
## Exclude deaths before 1st follow-up point and prevalent cases:
cc.group[timedth < time.1st | prevchd==1 | prevmi==1 | prevstrk==1] <- "Excluded"
})
control.id <- dlply(framingham,
.(agegr=cut(age, 3:7*10)),
function(x) with(x, sample(randid[cc.group=="Control"],
sum(cc.group=="Case"))))
control.id <- unlist(control.id)
View(framingham)
casedata <- merge(case.id, framingham, by="randid")
casedata <- merge(case.id2, framingham, by="randid")
casedata <- merge(case.id1, framingham, by="randid")
View(case.id1)
controldata <- merge(control.id, framingham, by="randid")
control.id <- dlply(framingham,
.(agegr=cut(age, 3:7*10)),
function(x) with(x, sample(randid[cc.group=="Control"],
sum(cc.group=="Case"))))
control.id <- unlist(control.id)
View(case.id1)
View(casedata)
install.packages("rmarkdown")
setwd("C:/Users/Paula/Documents/GitHub/IODS-project/data")
setwd("C:/Users/Paula/Documents/GitHub/IODS-project/data")
mat<-read.table("student-mat.csv",header=T,sep=",")
mat<-read.table("student-mat.csv",header=T,sep=";")
por<-read.table("student-por.csv",header=T,sep=";")
str(mat)
dim(mat)
dim(por)
str(por)
names(mat)
names(por)
library(dplyr)
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu",
"Mjob","Fjob","reason","nursery","internet")
math_por <- inner_join(math, por, by = join_by)
mat_por <- inner_join(mat, por, by = join_by)
mat_por<-inner_join(mat,por,by=join_by,suffix=c(".math",".por"))
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu",
"Mjob","Fjob","reason","nursery","internet")
mat_por <- inner_join(mat, por, by = join_by)
mat_por<-inner_join(mat,por,by=join_by,suffix=c(".mat",".por"))
names(mat_por)
View(mat)
alc <- select(mat_por, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(mat)[!colnames(mat) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(mat_por, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- select(two_columns, 1)[[1]]
}
}
dim(mat_por)
str(mat_por)
alc$alc_use<-mean(Dalc,Walc)
alc$alc_use<-mean(alc$Dalc,alc$Walc)
alc$alc_use<-(alc$Dalc+alc$Walc)/2
alc$alc_use
alc$high_use<-ifelse(alc$alc_use>2,TRUE,FALSE)
View(alc)
glimpse(alc)
write.csv("alc.csv",alc)
write.csv(alc,"alc.csv")
read.table("alc.csv",header=T)
alc<-read.table("alc.csv",header=T)
alc<-read.table("alc.csv",header=T,sep=";")
View(alc)
alc<-read.table("alc.csv",header=T,sep=",")
write.csv(alc,"alc.csv",row.names=F)
alc<-read.table("alc.csv",header=T,sep=",")
alc<-read.table("alc.csv",header=T,sep=",")
View(alc)
write.csv(alc,"alc.csv",row.names=F)
alc<-read.table("alc.csv",header=T,sep=",")
#################
#Paula Bergman
#7.2.2017
#Data wrangling to create the alcohol consumption dataset
#Data downloaded from the website
#https://archive.ics.uci.edu/ml/machine-learning-databases/00356/
#Set the working directory
setwd("C:/Users/Paula/Documents/GitHub/IODS-project/data")
#Read the datasets into RStudio
mat<-read.table("student-mat.csv",header=T,sep=";")
por<-read.table("student-por.csv",header=T,sep=";")
#Check the dimensions and the structure of the datasets
dim(mat)
str(mat)
#We can see that the mat-data  consists of 395 observations and 33 variables,
#17 of which are of type factor and the rest integer.
dim(por)
str(por)
#We can see that the por-data consists of 649 observations and 33 variables,
#which are exactly the same than in the mat-data.
#Access the dplyr library
library(dplyr)
#Join the datasets by using the variables "school", "sex", "age", "address",
#"famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason", "nursery",
#"internet" as (student) identifiers. This way only the students present in
#both datasets will be included in the data
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu",
"Mjob","Fjob","reason","nursery","internet")
mat_por <- inner_join(mat, por, by = join_by)
mat_por<-inner_join(mat,por,by=join_by,suffix=c(".mat",".por"))
dim(mat_por)
str(mat_por)
#Now the dataset has 382 observations and 53 variables. Those variables that I
#used for joining, are there only once but for the rest of the variables there are
#two of each, separated with the endings .mat and .por
#Create a new data frame with only the joined columns
alc <- select(mat_por, one_of(join_by))
#The columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(mat)[!colnames(mat) %in% join_by]
#For every column name not used for joining...
for(column_name in notjoined_columns) {
#select two columns from 'math_por' with the same original name
two_columns <- select(mat_por, starts_with(column_name))
#select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
#if that first column vector is numeric...
if(is.numeric(first_column)) {
#take a rounded average of each row of the two columns and
#add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
#add the first column vector to the alc data frame
alc[column_name] <- select(two_columns, 1)[[1]]
}
}
#Create an alcohol consumption variable alc_use to the joined data by
#taking the average of alcohol consumption variables in the data.
#Those are Dalc = Daily alcohol consumption and Walc = Weekly alcohol consumption
alc$alc_use<-(alc$Dalc+alc$Walc)/2
#Create a variable high_use to the joined data to describe whether the student
#uses alcohol a high amount or not
alc$high_use<-ifelse(alc$alc_use>2,TRUE,FALSE)
#Glimpse at the joined and modified data to make sure everything is in order
glimpse(alc)
write.csv(alc,"alc.csv",row.names=F)
alc<-read.table("alc.csv",header=T,sep=",")
alc<-read.table("alc.csv",header=T,sep=",")
names(alc)
setwd("C:/Users/Paula/Documents/GitHub/IODS-project/data")
